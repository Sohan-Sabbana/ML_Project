# !pip install yfinance tensorflow

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import yfinance as yf
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM
import math
from sklearn.metrics import mean_squared_error

# ==========================================
# 1. DATA COLLECTION & VISUALIZATION
# ==========================================

# Download AAPL data from Yahoo Finance
# You can change 'AAPL' to any stock ticker (e.g., 'GOOG', 'TSLA')
df = yf.download('AAPL', start='2015-01-01', end='2024-01-01')

# Extract only the 'Close' column
df1 = df['Close']

# Plot the original close price
plt.figure(figsize=(10,6))
plt.plot(df1)
plt.title("AAPL Close Price History")
plt.xlabel('Date')
plt.ylabel('Close Price USD ($)')
plt.show()

# ==========================================
# 2. DATA PREPROCESSING
# ==========================================

# LSTM is sensitive to the scale of the data, so we apply MinMax Scaling
scaler = MinMaxScaler(feature_range=(0,1))
df1 = scaler.fit_transform(np.array(df1).reshape(-1,1))

# Split dataset into train and test split (65% Train, 35% Test)
training_size = int(len(df1) * 0.65)
test_size = len(df1) - training_size
train_data, test_data = df1[0:training_size,:], df1[training_size:len(df1),:1]

# Function to create a dataset matrix with time steps
# Converts an array of values into a dataset matrix
def create_dataset(dataset, time_step=1):
    dataX, dataY = [], []
    for i in range(len(dataset)-time_step-1):
        a = dataset[i:(i+time_step), 0]   # i=0, 0,1,2,3-----99   100 
        dataX.append(a)
        dataY.append(dataset[i + time_step, 0])
    return np.array(dataX), np.array(dataY)

# Reshape into X=t, t+1, t+2...t+99 and Y=t+100
time_step = 100
X_train, y_train = create_dataset(train_data, time_step)
X_test, ytest = create_dataset(test_data, time_step)

# Reshape input to be [samples, time steps, features] which is required for LSTM
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

print(f"Training Shape: {X_train.shape}")
print(f"Testing Shape: {X_test.shape}")

# ==========================================
# 3. BUILD AND TRAIN LSTM MODEL
# ==========================================

model = Sequential()
# Layer 1
model.add(LSTM(50, return_sequences=True, input_shape=(100,1)))
# Layer 2
model.add(LSTM(50, return_sequences=True))
# Layer 3
model.add(LSTM(50))
# Output Layer
model.add(Dense(1))

model.compile(loss='mean_squared_error', optimizer='adam')

model.summary()

# Train the model
# Note: You can adjust epochs and batch_size based on your computational power
model.fit(X_train, y_train, validation_data=(X_test, ytest), epochs=100, batch_size=64, verbose=1)

# ==========================================
# 4. PREDICTION AND EVALUATION
# ==========================================

# Lets Do the prediction
train_predict = model.predict(X_train)
test_predict = model.predict(X_test)

# Transform back to original form
train_predict = scaler.inverse_transform(train_predict)
test_predict = scaler.inverse_transform(test_predict)
y_train_inv = scaler.inverse_transform(y_train.reshape(-1, 1))
ytest_inv = scaler.inverse_transform(ytest.reshape(-1, 1))

# Calculate RMSE performance metrics
train_rmse = math.sqrt(mean_squared_error(y_train_inv, train_predict))
test_rmse = math.sqrt(mean_squared_error(ytest_inv, test_predict))

print(f"Train RMSE: {train_rmse}")
print(f"Test RMSE: {test_rmse}")

# Plotting
# Shift train predictions for plotting
look_back = 100
trainPredictPlot = np.empty_like(df1)
trainPredictPlot[:, :] = np.nan
trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict

# Shift test predictions for plotting
testPredictPlot = np.empty_like(df1)
testPredictPlot[:, :] = np.nan
testPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1, :] = test_predict

# Plot baseline and predictions
plt.figure(figsize=(12,6))
plt.plot(scaler.inverse_transform(df1), label='Original Data')
plt.plot(trainPredictPlot, label='Train Prediction')
plt.plot(testPredictPlot, label='Test Prediction')
plt.title("Model Predictions vs Actual Data")
plt.legend()
plt.show()

# ==========================================
# 5. FORECASTING NEXT 30 DAYS
# ==========================================

# Taking the last 100 days data from the test data to predict the future
x_input = test_data[len(test_data)-100:].reshape(1,-1)
temp_input = list(x_input)
temp_input = temp_input[0].tolist()

# Logic to predict the next 30 days
lst_output = []
n_steps = 100
i = 0

while(i < 30):
    if(len(temp_input) > 100):
        x_input = np.array(temp_input[1:])
        x_input = x_input.reshape(1, -1)
        x_input = x_input.reshape((1, n_steps, 1))
        
        yhat = model.predict(x_input, verbose=0)
        
        temp_input.extend(yhat[0].tolist())
        temp_input = temp_input[1:]
        lst_output.extend(yhat.tolist())
        i = i + 1
    else:
        x_input = x_input.reshape((1, n_steps, 1))
        yhat = model.predict(x_input, verbose=0)
        
        temp_input.extend(yhat[0].tolist())
        lst_output.extend(yhat.tolist())
        i = i + 1

# Creating a new plot for the forecast
day_new = np.arange(1, 101)
day_pred = np.arange(101, 131)

plt.figure(figsize=(10,6))
# Plotting the last 100 days of real data
plt.plot(day_new, scaler.inverse_transform(df1[len(df1)-100:]), label='History (Last 100 Days)')
# Plotting the predicted 30 days
plt.plot(day_pred, scaler.inverse_transform(lst_output), label='Forecast (Next 30 Days)')
plt.title("30 Day Future Forecast")
plt.legend()
plt.show()
